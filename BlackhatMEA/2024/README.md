This talk demonstrates **Adversarial AI operations** by walking through each phase of the process, supported by live demos that reveal how Large Language Models (LLMs) can fail under different adversarial scenarios.

We also showcase how to **automate these operations** using [PyRIT](https://github.com/Azure/PyRIT), Microsoft's open-source red teaming framework for LLMs, allowing for scalable, repeatable testing across various attack types.



## Case Study 2 
https://github.com/user-attachments/assets/c26f65b8-3843-4b9a-9641-42eab7cf5890

## PyRIT DEMO 
https://github.com/user-attachments/assets/91cc9594-8299-48ab-9013-2d4ff9576d80

